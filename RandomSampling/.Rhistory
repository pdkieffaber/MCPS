# The test data is just the data for the current fold 'i'
test_data  <- cars_folded %>% filter(fold == i)
# The training data is everything else
train_data <- cars_folded %>% filter(fold != i)
# c. Model: Build *only* on the training data
model <- lm(dist ~ speed, data = train_data)
# d. Predict: Test on the hold-out fold
predictions <- predict(model, newdata = test_data)
# e. Store R-squared from the *test* data
# We have to calculate R-squared manually from the test predictions
ss_total <- sum((test_data$dist - mean(test_data$dist))^2)
ss_resid <- sum((test_data$dist - predictions)^2)
fold_r2s[i] <- 1 - (ss_resid / ss_total)
}
# 5. Finish
print("R-squared from each of the 5 folds:")
print(round(fold_r2s, 3))
print(paste("Average Cross-Validated R-squared:", round(mean(fold_r2s), 3)))
# Compare this to the "overly optimistic" R-squared
optimistic_r2 <- summary(lm(dist ~ speed, data = cars))$r.squared
print(paste("Optimistic R-squared from the full dataset:", round(optimistic_r2, 3)))
head(cars_folded)
sum(cars_folded$fold==1)
sum(cars_folded$fold==2)
sum(cars_folded$fold==3)
sum(cars_folded$fold==4)
sum(cars_folded$fold==5)
sample(1:5, size=10)
sample(1:5, size=10, replace=TRUE)
library(tidyverse)
# 1. Add a "fold" ID to our data
# We'll use 5 folds for this example
data(cars)
set.seed(123) # for reproducibility
cars_folded <- cars %>%
mutate(fold = sample(1:5, size = nrow(cars), replace = TRUE))
# 2. Initialize
# Create an empty vector to store our 5 R-squared values
fold_r2s <- numeric(5) # We have 5 folds
# 3. Loop
for (i in 1:5) {
# a/b. Split into training and testing
# The test data is just the data for the current fold 'i'
test_data  <- cars_folded %>% filter(fold == i)
# The training data is everything else
train_data <- cars_folded %>% filter(fold != i)
# c. Model: Build *only* on the training data
model <- lm(dist ~ speed, data = train_data)
# d. Predict: Test on the hold-out fold
predictions <- predict(model, data = test_data)
# e. Store R-squared from the *test* data
# We have to calculate R-squared manually from the test predictions
ss_total <- sum((test_data$dist - mean(test_data$dist))^2)
ss_resid <- sum((test_data$dist - predictions)^2)
fold_r2s[i] <- 1 - (ss_resid / ss_total)
}
# 5. Finish
print("R-squared from each of the 5 folds:")
print(round(fold_r2s, 3))
print(paste("Average Cross-Validated R-squared:", round(mean(fold_r2s), 3)))
# Compare this to the "overly optimistic" R-squared
optimistic_r2 <- summary(lm(dist ~ speed, data = cars))$r.squared
print(paste("Optimistic R-squared from the full dataset:", round(optimistic_r2, 3)))
library(tidyverse)
# 1. Add a "fold" ID to our data
# We'll use 5 folds for this example
data(cars)
set.seed(123) # for reproducibility
cars_folded <- cars %>%
mutate(fold = sample(1:5, size = nrow(cars), replace = TRUE))
# 2. Initialize
# Create an empty vector to store our 5 R-squared values
fold_r2s <- numeric(5) # We have 5 folds
# 3. Loop
for (i in 1:5) {
# a/b. Split into training and testing
# The test data is just the data for the current fold 'i'
test_data  <- cars_folded %>% filter(fold == i)
# The training data is everything else
train_data <- cars_folded %>% filter(fold != i)
# c. Model: Build *only* on the training data
model <- lm(dist ~ speed, data = train_data)
# d. Predict: Test on the hold-out fold
predictions <- predict(model, newdata = test_data)
# e. Store R-squared from the *test* data
# We have to calculate R-squared manually from the test predictions
ss_total <- sum((test_data$dist - mean(test_data$dist))^2)
ss_resid <- sum((test_data$dist - predictions)^2)
fold_r2s[i] <- 1 - (ss_resid / ss_total)
}
# 5. Finish
print("R-squared from each of the 5 folds:")
print(round(fold_r2s, 3))
print(paste("Average Cross-Validated R-squared:", round(mean(fold_r2s), 3)))
# Compare this to the "overly optimistic" R-squared
optimistic_r2 <- summary(lm(dist ~ speed, data = cars))$r.squared
print(paste("Optimistic R-squared from the full dataset:", round(optimistic_r2, 3)))
# This chunk sets up the R environment for the rest of the document
knitr::opts_chunk$set(
echo = TRUE,       # Show the R code
message = FALSE,   # Hide messages
warning = FALSE,   # Hide warnings
fig.align = "center", # Center plots
out.width = '70%'
)
library(ggplot2)
knitr::opts_chunk$set(
echo = TRUE, message = FALSE, warning = FALSE,
fig.width = 7, fig.height = 4.8, dpi = 150
)
# --- Part 1: Your Personalized Assignment ---
# --- Run this block ONCE to get your variables ---
# Load libraries
library(WDI)         # For World Bank data
library(tidyverse)   # For all data manipulation
library(lme4)        # For Linear Mixed Models
library(lmerTest)    # For LMM p-values
library(car)         # For Anova()
library(tidymodels)  # For rsample and the "tidy" workflow
install.packages("tidymodels")
# --- Part 1: Your Personalized Assignment ---
# --- Run this block ONCE to get your variables ---
# Load libraries
library(WDI)         # For World Bank data
library(tidyverse)   # For all data manipulation
library(lme4)        # For Linear Mixed Models
library(lmerTest)    # For LMM p-values
library(car)         # For Anova()
library(tidymodels)  # For rsample and the "tidy" workflow
# --- Part 1: Your Personalized Assignment ---
# --- Run this block ONCE to get your variables ---
# Load libraries
library(WDI)         # For World Bank data
library(tidyverse)   # For all data manipulation
library(lme4)        # For Linear Mixed Models
library(lmerTest)    # For LMM p-values
library(car)         # For Anova()
#library(tidymodels)  # For rsample and the "tidy" workflow
library(lattice)     # For qqmath
library(digest)      # For hashing your name to a seed
# --- !! ENTER YOUR NAME HERE !! ---
# Type your full name inside the quotes. This makes your assignment unique.
YOUR_NAME <- "STUDENT NAME GOES HERE"
# --- !! (No, really, change it to your name) !! ---
if (YOUR_NAME == "STUDENT NAME GOES HERE") {
warning("Please change YOUR_NAME to your actual name to get your unique assignment.")
}
# Create a unique, reproducible seed from your name
hex_hash <- digest(YOUR_NAME, algo = "crc32", serialize = FALSE)
hex_substr <- substr(hex_hash, 1, 7)
student_seed <- strtoi(hex_substr, base = 16L)
set.seed(student_seed) # Set the seed!
# 1. Define the variable pools
dv_pool <- c(
"suicide_rate_per100k" = "SH.STA.SUIC.P5", # Health Psych
"life_expectancy" = "SP.DYN.LE00.IN",      # Health Psych
"school_enroll_primary" = "SE.PRM.ENRR"   # Developmental Psych
)
continuous_iv_pool <- c(
"gdp_per_cap" = "NY.GDP.PCAP.CD",      # Social Determinant
"health_exp_gdp" = "SH.XPD.CHEX.GD.ZS", # Health Policy
"fertility_rate" = "SP.DYN.TFRT.IN",    # Social
"internet_users_pct" = "IT.NET.USER.ZS" # Social/Cog Psych
)
# 2. Randomly select your variables
selected_dv_code <- sample(dv_pool, 1)
selected_iv_codes <- sample(continuous_iv_pool, 2)
# These are your personalized variable codes
my_dv_code <- selected_dv_code[[1]]
my_iv1_code <- selected_iv_codes[[1]]
my_iv2_code <- selected_iv_codes[[2]]
# These are your personalized variable NAMES (for R code)
YOUR_DV <- names(selected_dv_code)
YOUR_IV1 <- names(selected_iv_codes)[1]
YOUR_IV2 <- names(selected_iv_codes)[2]
# 3. Print the assignment
cat("--- YOUR UNIQUE CAPSTONE ASSIGNMENT ---",
"\nYour Name:", YOUR_NAME,
"\nYour Reproducible Seed:", student_seed,
"\n\n--- YOUR VARIABLES (Psychology/Policy Focus) ---",
"\n1. Your Dependent Variable (DV) is:", YOUR_DV, "(", my_dv_code, ")",
"\n2. Your first Continuous IV is:", YOUR_IV1, "(", my_iv1_code, ")",
"\n3. Your second Continuous IV is:", YOUR_IV2, "(", my_iv2_code, ")",
"\n4. Your grouping variables will be: region, income, and country.",
"\n\n--- COPY THE CODE BELOW FOR PART 2 ---",
"\n# This is the R code to pull your indicators",
"\nmy_dv_indicator <- \"", my_dv_code, "\"",
"\nmy_iv1_indicator <- \"", my_iv1_code, "\"",
"\nmy_iv2_indicator <- \"", my_iv2_code, "\"",
"\n"
)
# --- Part 1: Your Personalized Assignment ---
# --- Run this block ONCE to get your variables ---
# Load libraries (you may need to install first)
library(WDI)
library(tidyverse)
library(lme4)
library(lmerTest)
library(car)
library(GGally)
library(lattice)
library(digest)
library(plyr)
library(broom.mixed)
# --- !! ENTER YOUR NAME !! ---
# Type your full name inside the quotes, replacing the text "STUDENT NAME GOES HERE".
YOUR_NAME <- "Paul"
# --- !! (No, really, change it to your name) !! ---
if (YOUR_NAME == "REPLACE_ME_WITH_YOUR_FULL_NAME") {
warning("Please change YOUR_NAME to your actual name to get your unique assignment.")
}
# Convert name to a number
# Create a unique, reproducible seed
# 1. Get the hex hash as a string
hex_hash <- digest(YOUR_NAME, algo = "crc32", serialize = FALSE)
# 2. Take the first 7 digits (this prevents an integer overflow)
hex_substr <- substr(hex_hash, 1, 7)
# 3. Convert the hex string (base-16) to a standard integer
student_seed <- strtoi(hex_substr, base = 16L)
set.seed(student_seed)
#Define the variable pools
dv_pool <- c(
"SP.DYN.LE00.IN",  # Life Expectancy
"SH.STA.SUIC.P5", # Suicide Rate
"SP.DYN.IMRT.IN" # Infant Mortality
)
dv_map<-c("SP.DYN.LE00.IN"="LifeExpectancy","SH.STA.SUIC.P5"="SuicideRate","SP.DYN.IMRT.IN"="InfantMortality")
continuous_iv_pool <- c(
"NY.GDP.PCAP.CD", #GDP per capita
"SE.PRM.ENRR",    #School enrollment
"SP.DYN.TFRT.IN",  #Fertility rate
"SH.XPD.CHEX.GD.ZS", #Health expenditure GDP
"EG.USE.ELEC.KH.PC" #Electric Consumption
)
iv_map<-c("NY.GDP.PCAP.CD"="Per Capita GDP", "SE.PRM.ENRR"="School Enrollment", "SP.DYN.TFRT.IN"="Fertility Rate", "SH.XPD.CHEX.GD.ZS"="Health Expenditure GDP", "EG.USE.ELEC.KH.PC"="Electricity Consumption")
# 2. Assign variables
selected_dv_code <- sample(dv_pool, 1)
selected_iv_codes <- sample(continuous_iv_pool, 3)
my_dv_code <- selected_dv_code[[1]]
my_iv1_code <- selected_iv_codes[[1]]
my_iv2_code <- selected_iv_codes[[2]]
my_iv3_code <- selected_iv_codes[[3]]
# These are your personalized variable NAMES (for R code)
# We will use these as column names
YOUR_DV <- revalue(selected_dv_code,dv_map)
YOUR_IV1 <- revalue(selected_iv_codes[1],iv_map)
YOUR_IV2 <- revalue(selected_iv_codes[2],iv_map)
YOUR_IV3 <- revalue(selected_iv_codes[3],iv_map)
# Categorical variables are assigned to everyone
YOUR_CAT_MULTI <- "region"
YOUR_CAT_BINARY <- "income_binary"
# 3. Print the assignment
cat("--- YOUR UNIQUE ASSIGNMENT ---",
"\nYour Name:", YOUR_NAME,
"\nYour Reproducible Seed:", student_seed,
"\n\n--- YOUR VARIABLES ---",
"\n1. Your Dependent Variable (DV) is:", YOUR_DV, "(", my_dv_code, ")",
"\n2. Your first Continuous IV is:", YOUR_IV1, "(", my_iv1_code, ")",
"\n3. Your second Continuous IV is:", YOUR_IV2, "(", my_iv2_code, ")",
"\n4. Your third Continuous IV is:" , YOUR_IV3, "(", my_iv3_code, ")",
"\n5. Your Multi-level Categorical IV is: region",
"\n6. Your Binary Categorical IV will be: income_binary (you will create this)",
"\n"
)
# --- These are all the indicators we need to pull ---
my_indicators <- c(
my_dv_code,
my_iv1_code,
my_iv2_code,
my_iv3_code
)
# Pull the data from 2000-2020
data_raw <- WDI(
indicator = indicators,
start = 2000,
end = 2020,
extra = TRUE # This adds region and income
)
clean_data=data_raw %>%
filter(region != "Aggregates") %>%
mutate(region=factor(region), income_binary=factor(ifelse(income=="High income","High Income","Low Income"))) %>%
na.omit()
region_summary <- clean_data %>%
group_by(region) %>%
dplyr::summarise(
avg = mean(SP.DYN.IMRT.IN, na.rm = TRUE)
)
test=lm(SP.DYN.IMRT.IN ~ region*income_binary, data=clean_data)
summary(test)
car::Anova(test,type=3)
install.packages("mlmRev"")
install.packages('mlmRev')
library(mlmRev)
data(highschoolandbeyond)
head(highschoolandbeyond)
head(data)
?highschoolandbeyond
head(HighSchoolAndBeyond)
data("Hsb82")
head(Hsb82)
?Hsb82
unique(Hsb82$minrty)
Hsb82$minrty %>% summarise(minrty, n())
Hsb82$minrty %>% summarise(minrty, function=n())
Hsb82$minrty %>% count(minrty)
Hsb82 %>% count(minrty)
Hsb82 %>% count(minrty)
Hsb82 %>%
count(minrty)
head(Hsb82)
Hsb82 %>% count(minrty)
Hsb82 %>% summarise(minrty=n())
Hsb82 %>% group_by(minrty) %>% summarise(test=n())
cat("\n'checker_6.rds' file has been created. Give this file to your students.")
# 3. Save the *function itself* to a binary file
saveRDS(check_my_work_6, file = "RandomSamplingChecker.rds")
# 3. Save the *function itself* to a binary file
saveRDS(check_my_work_6, file = "checker_6.rds")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
# --- 1. Load all required libraries ---
library(mlmRev)      # For the Hsb82 dataset
library(tidyverse)   # For all data manipulation
library(lme4)        # For Linear Mixed Models (lmer)
library(lmerTest)    # For LMM p-values
library(car)         # For Anova()
library(digest)      # For hashing your name to a seed
# --- 2. !! ENTER YOUR NAME HERE !! ---
YOUR_NAME <- "STUDENT NAME GOES HERE"
# --- !! (No, really, change it to your name) !! ---
if (YOUR_NAME == "STUDENT NAME GOES HERE") {
warning("Please change YOUR_NAME to your actual name to get your unique assignment.")
}
# --- 3. Generate your unique seed ---
hex_hash <- digest(YOUR_NAME, algo = "crc32", serialize = FALSE)
hex_substr <- substr(hex_hash, 1, 7)
student_seed <- strtoi(hex_substr, base = 16L)
# --- 4. Set the seed ---
set.seed(student_seed)
# --- 5. Load and create your unique dataset ---
data(Hsb82) # Load the dataset
# This is your unique "slice" of the data
my_data <- Hsb82 %>%
sample_frac(0.95) # Take a 95% random slice
# --- 6. Print a verification message ---
cat("--- DATASET GENERATED ---",
"\nYour Name:", YOUR_NAME,
"\nYour Seed:", student_seed,
"\nYour unique dataset 'my_data' has", nrow(my_data), "rows.",
"\nUse 'my_data' for all analysis.",
"\n\n--- Your 'my_data' Head ---")
print(head(my_data))
# --- 1. Load all required libraries ---
library(mlmRev)      # For the Hsb82 dataset
library(tidyverse)   # For all data manipulation
library(lme4)        # For Linear Mixed Models (lmer)
library(lmerTest)    # For LMM p-values
library(car)         # For Anova()
library(digest)      # For hashing your name to a seed
# --- 2. !! ENTER YOUR NAME HERE !! ---
YOUR_NAME <- "STUDENT NAME GOES HERE"
# --- !! (No, really, change it to your name) !! ---
if (YOUR_NAME == "STUDENT NAME GOES HERE") {
warning("Please change YOUR_NAME to your actual name to get your unique assignment.")
}
# --- 3. Generate your unique seed ---
hex_hash <- digest(YOUR_NAME, algo = "crc32", serialize = FALSE)
hex_substr <- substr(hex_hash, 1, 7)
student_seed <- strtoi(hex_substr, base = 16L)
# --- 4. Set the seed ---
set.seed(student_seed)
# --- 5. Load and create your unique dataset ---
data(Hsb82) # Load the dataset
# This is your unique "slice" of the data
my_data <- Hsb82 %>%
sample_frac(0.95) # Take a 95% random slice
# --- 6. Print a verification message ---
cat("--- DATASET GENERATED ---",
"\nYour Name:", YOUR_NAME,
"\nYour Seed:", student_seed,
"\nYour unique dataset 'my_data' has", nrow(my_data), "rows.",
"\nUse 'my_data' for all analysis.",
"\n\n--- Your 'my_data' Head ---")
# --- 1. Load all required libraries ---
library(mlmRev)      # For the Hsb82 dataset
library(tidyverse)   # For all data manipulation
library(lme4)        # For Linear Mixed Models (lmer)
library(lmerTest)    # For LMM p-values
library(car)         # For Anova()
library(digest)      # For hashing your name to a seed
# --- 2. !! ENTER YOUR NAME HERE !! ---
YOUR_NAME <- "STUDENT NAME GOES HERE"
# --- !! (No, really, change it to your name) !! ---
if (YOUR_NAME == "STUDENT NAME GOES HERE") {
warning("Please change YOUR_NAME to your actual name to get your unique assignment.")
}
# --- 3. Generate your unique seed ---
hex_hash <- digest(YOUR_NAME, algo = "crc32", serialize = FALSE)
hex_substr <- substr(hex_hash, 1, 7)
student_seed <- strtoi(hex_substr, base = 16L)
# --- 4. Set the seed ---
set.seed(student_seed)
# --- 5. Load and create your unique dataset ---
data(Hsb82) # Load the dataset
# This is your unique "slice" of the data
my_data <- Hsb82 %>%
sample_frac(0.95) # Take a 95% random slice
# --- 6. Print a verification message ---
cat("--- DATASET GENERATED ---",
"\nYour Name:", YOUR_NAME,
"\nYour Seed:", student_seed,
"\nYour unique dataset 'my_data' has", nrow(my_data), "rows.",
"\nUse 'my_data' for all analysis.")
?VarCorr
head(Hsb82)
sample(HSB82$sx,10)
sample(Hsb82$sx,10)
sample(Hsb82$sx,10)
# --- Run this chunk once to load the check_my_work() function ---
check_my_work_6 <- readRDS("checker_6_final.rds")
setwd("~/Documents/MCPS/RandomSampling")
source("~/Documents/MCPS/RandomSampling/RandomSamplingChecker.R")
# --- Run this chunk once to load the check_my_work() function ---
check_my_work_6 <- readRDS("RandomSamplingChecker.rds")
?RandomSamplingChecker
?check_my_work_6
View(check_my_work_6)
# --- Fill in your name and answers, then run! ---
check_my_work_6(
your_name = "STUDENT NAME GOES HERE", # Must match Part 1
# Your 6 saved values from Part 2:
task1_ses_coef        = 1,#task1_ses_coef,
task2_f_stat          = 2,#task2_f_stat,
task3_intercept_var   = 3,#task3_intercept_var,
task4_perm_p_value    = 4,#task4_perm_p_value,
task5_median_ci_upper = 5,#task5_median_ci_upper,
task6_cv_rmse         = 6#task6_cv_rmse
)
my_data
names(my_data)
linmod=lm(mAch~meanses,data=my_data)
summary(linmod)
size(my_data)
dim(my_data)
lengh(unique(my_data$school))
length(unique(my_data$school))
unique(my_data$sector)
car::Anova(linmod,type=3)
test=car::Anova(linmod,type=3)
test["meanses"]
test
test["DF"]
test$`F value`
test$`F value`[2]
car::Anova(linmod,type=3)$`F value`[2]
set.seed(23)
sample(1:10,5)
sample(1:10,5)
set.seed(23)
sample(1:10,5)
sample(1:10,5)
summary(linmod)
confint(linmod)
coef(linmod)[2]
coef(linmod)[1]
coef(linmod)[3]
coef(linmod)[2,]
coef(linmod)[2]
coef(linmod)$2.5
coef(linmod)
confint(linmod)$2.5
confint(linmod)
test=confint(linmod)
test
test[1]
test[2]
test[3]
test[4]
quantile(1:100,c(.05,.95))
library(lme4)
library(lmerTesrt)
library(lmerTest)
model_intercepts <- lmer(mAch ~ ses + (1 | school), data = my_data)
summary(model_intercepts)
tidy(model_intercepts, effects = "fixed")
names(my_data)
knitr::opts_chunk$set(echo = TRUE,out.width='70%',fig.align='center')
library(patchwork)
p1 <- ggplot(my_data, aes(x = ses)) + geom_histogram()
p2 <- ggplot(my_data, aes(x = mAch)) + geom_histogram()
p1+p2
head(my_data)
library(HSAUR2)
install.packages("HSAUR2")
library(HSAUR2)
help(HSAUR2)
data(HELPrct)
head(HELPrct)
# Let's plot the number of drinks (i1) by sex
ggplot(HELPrct, aes(x = i1, fill = sex)) +
geom_histogram(binwidth = 5, alpha = 0.8, position = "identity") +
labs(title = "Daily Drinks (i1) by Sex",
x = "Average Drinks Per Day",
subtitle = "Data is extremely right-skewed with outliers") +
theme_minimal()
print(head(HELPrct))
install.packages("HSAUR2")
library(HSAUR2)
data(HELPrct)
head(HELPrct)
load(file.path(find.package("HSAUR2"), "data", "HELPrct.rda"))
load(url("http://www.biostat.uni-frankfurt.de/packages/HSAUR2/data/HELPrct.rda"))
